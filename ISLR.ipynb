{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# An Introduction to Statistical Learning\n",
    "with Applications in `R`  \n",
    "Second Edition  \n",
    "Gareth James $\\cdot$ Daniela Witten $\\cdot$ Trevor Hastie $\\cdot$ Robert Tibshirani  \n",
    "\n",
    "Notes by Bonnie Cooper and working out the examples in `Python`  \n",
    "for the course, DATA 622: Machine Learning and Big Data  \n",
    "\n",
    "\n",
    "<img src=\"https://images-na.ssl-images-amazon.com/images/I/41pP5+SAv-L._SX330_BO1,204,203,200_.jpg\" width=\"20%\" style=\"margin-left:auto; margin-right:auto\">\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**statistical learning** - making sense of complex data sets  \n",
    "**supervised statistical learning** - building a statistical model for predicting or estimating an output based on one of more inputs  \n",
    "**unsupervised statistical learning** - there are inputs, but no supervising outputs; nevertheless, we can learn about relationships and structure in the data.  \n",
    "\n",
    "The goal of this book: become informed users. for technical detail, work through the [ESL](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)  \n",
    "*While it is important to know what job is performed by each cog, it is not necessary to have the skills to construct the machine inside the box!*  \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### Notation\n",
    "\n",
    "* $n$ - number of distinct data points\n",
    "* $p$ - number of feature variables\n",
    "* $\\mathbf{X}$ - an $n \\times p$ matrix whose $(i,j)$th element is represented as $x_{ij}$\n",
    "* $\\mathbf{y}$ - the set of all $n$ observations in vector form\n",
    "* $a \\in \\mathbb{R}$ - a scalar\n",
    "* $a \\in \\mathbb{R}^k$ - a vector with length k\n",
    "* $a \\in \\mathbb{R}^[k\\times d]$ - a matix\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2 Statistical Learning\n",
    "\n",
    "$\\mathbf{X}$ - the response or dependent variable  \n",
    "$\\mathbf{Y}$ - the predictor(s), independent variable(s) or feature(s)  \n",
    "\n",
    "We assume that there is a relationship between $\\mathbf{Y}$ and $\\mathbf{X}$ such that:  \n",
    "$$\\mathbf{Y} = f(\\mathbf{X}) + \\epsilon $$\n",
    "\n",
    "where:  \n",
    "$f$ - some fixed function (undetermined)  \n",
    "$\\epsilon$ - a random error term  \n",
    "\n",
    "Our goal: estimate $f$ based on the given observations  \n",
    "\n",
    "### What is Statistical Learning?\n",
    "\n",
    "#### Why Estimate $f$?\n",
    "\n",
    "**Prediction** - predict $\\mathbf{Y}$ using $\\hat{ \\mathbf{Y} } = \\hat{f} (\\mathbf{X})$  \n",
    "The accuracy of $\\hat{\\mathbf{Y}}$ depends on two quantities: the reducible error and the irreducible error  \n",
    "**reducible error** - error in our estimate of $f$  \n",
    "**irreducible error** - error in $\\mathbf{Y}$  \n",
    "**expected value** - the squared difference between the actual and the estimated value of $\\mathbf{Y}$  \n",
    "\n",
    "$$\\mathbf{E}(\\mathbf{Y}- \\hat{\\mathbf{Y}})^2 = \\mathbf{E}[f(\\mathbf{X}+\\epsilon -\\hat{f}(\\mathbf{X})]^2] = [f(\\mathbf{X})-\\hat{f}(\\mathbf{X})]^2 + \\mbox{Var}(\\epsilon)$$\n",
    "\n",
    "\n",
    "**Inference** - understand the association between $\\mathbf{Y}$ and $\\mathbf{X}_1,\\dots,\\mathbf{X}_p$  \n",
    "\n",
    "#### How Do We Estimate $f$?\n",
    "\n",
    "Our goal is to apply statistical learning to our training data to estimate the unknown function $f$. Basically, we want to find an estimate of $f$ which we will call $\\hat{f}$ such the $\\mathbf{Y}  \\approx \\hat{f}( \\mathbf{X})$  \n",
    "\n",
    "* **Paramteric approach** - involves a two-step model-based  \n",
    "    * make an assumption about the form of the data (ex: assume linearity)\n",
    "    * use a procudure to train and fit the assumed model\n",
    "    * problem: the model we chose will usually not match the true form of $f$\n",
    "* **Nonparametric methods** - make no assumptions about the form of $f$   \n",
    "    * estimate $f$ by getting as close to data points\n",
    "    * problem: since nonparametric methods do not reduce the problem of estimating $f$ to a small number of parameters, a comparatively larger number of observations are required in order to get an accurate estimate of $f$.\n",
    "    \n",
    "#### The Trade off Between Prediction Accuracy and Model Interpretability\n",
    "\n",
    "*Why would we ever choose to use a more restrictive method instead of a very flexible approach?*   \n",
    "Often, more restrictive models (e.g. linear regression) are more easily interpretable. However, in some settings we are only interested in the prediction, and the interpretability of the predictive model is simply not of interest; here we might expect that it will be best to use the more flexible model provided the model does not overfit.  \n",
    "\n",
    "#### Supervised Vs Unsupervised Learning \n",
    "\n",
    "**Supervised Learning** - for each observation of the predictor measurement, there is an associated response measure. Goal: fit a model that relates the response to the predictors so that we may (1) accurately predict future responses from the observations and (2) better understand the relationship between the response and the predictors.  \n",
    "**Unsupervised Learning** - for every observation, we observe a vector of features, but no associated response. This situation is called unsupervised, because we lack a response variable that can supervise our analysis.  \n",
    "\n",
    "#### Regression vs Classification Problems\n",
    "\n",
    "**quantitive variables** - take on numeric values  \n",
    "**qualitative variables** - take on categorical values  \n",
    "**regression problems** - the reponse is a quantitative variable\n",
    "**classification problems** - the response is a qualitative variable  \n",
    "most of the statistical learning methods discussed in this book can be applied regardless of the predictor variable type, provided that any qualitative predictors are properly coded before the analysis is performed.  \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing Model Accuracy\n",
    "\n",
    "*There is no free lunch in statistics* - no onemethod dominates all others over all possible data sets  \n",
    "\n",
    "#### Measureing Quality of Fit\n",
    "\n",
    "**mean squared error** -a measure of how well a models predictions acutally match the observed data. The MSE will be small if the predicted responses are very close to the truw responses and will be large if for some of the observations, the predicted and true responses differ substantially.   \n",
    "$$\\mathbf{MSE} = \\frac{1}{n} \\sum_{i=1}^{n}( y_i - \\hat{f} (x_i))^2$$\n",
    "We are interested in the accuracy of the predictions that we obtain when we apply out method to previously unseen test data. We want to choose the method which gives the lowest *test* MSE, as opposed to the lowest *traininng* MSE. In other words, we'd like to select a model that minimizes:  \n",
    "$$\\mathbf{Ave}(y_0 - \\hat{f}(x_0))^2$$\n",
    "where $(x_0,y_0)$ is a previously unseen test observation not ued to train the model.  \n",
    "\n",
    "**overfitting** - when a given method yields a small training $\\mathbf{MSE}$ but a large test $\\mathbf{MSE}$. When a less flexible model would have given a lower test $\\mathbf{MSE}$   \n",
    "\n",
    "#### The Bias-Variance Trade-Off  \n",
    "\n",
    "the Expected test $\\mathbf{MSE}$, for a given value of $x_0$ can always be decomposed into the sum of three fundamental qualities: the variance of $\\hat{f} (x_0)$, the square of the bias of $\\hat{f} (x_0)$ and the variance of the error terms $\\epsilon$:  \n",
    "$$\\mathbf{E}(y_0 - \\hat{f}(x_0))^2) = \\mathbf{Var}(\\hat{f}(x_0)) + [\\mathbf{Bias}(\\hat{f}(x_0))]^2 + \\mathbf{Var}(\\epsilon)$$\n",
    "\n",
    "What this tells is is, that in order to minimize the expected test error, we need to select a statistical learning method that simultaniously achieves **low variance** nd **low bias**. where:  \n",
    "**variance** - the amount that $\\hat{f}$ would change if we estimated it using a different training set. If a methods has high variance, then a small change to the data set would lead to a large change in $\\hat{f}$  \n",
    "**bias** - the error that is introduced by approximaating a real-life problem (choice of estimating $f$)  \n",
    "\n",
    "In general, as we use more flexible methods, the variance will increase and the bias will decrease.  \n",
    "**bias-variance trade-off** - the relationship between bias, variance, and test $\\mathbf{MSE}$. The challenge lies in finding a method for which both the variance and the squared bias are low.   \n",
    "\n",
    "#### The Classification Setting  \n",
    "\n",
    "Quantifying accuracy of a classification problem: the training error rate  \n",
    "$$\\frac{1}{n}\\sum_{i=1}^n \\mathbf{I}(y_1 \\neq \\hat{y}_i)$$\n",
    "**error rate**  - proportion of mistakes that are made if we apply our estimate $\\hat{f}$ to the training observations  \n",
    "**test error rate** $\\mathbf{Ave}(\\mathbf{I}(y_0 \\neg \\hat{y}_0))$ a good classifier is one for which the test error is smallest.  \n",
    "\n",
    "##### The Bayes Classifier \n",
    "\n",
    "**Bayes Classifier** - assign each observation to the most likely class, given its predictor values.\n",
    "$$\\mathbf{Pr}( Y= j | X = x_0 )$$\n",
    "**Bayesian Decision Boundary** boundary in feature space where the conditional probability of either events is equal. An observation that falls on one side of the boundary will be classified as one class whereas the other side the other.\n",
    "A Bayes Classifier produces the lowest possible test error rate, the **Bayes Error Rate**. the Bayes error rate is analogous to the irreducible error.  \n",
    "$$1 - \\mathbf{E}(max_j \\mathbf{Pr}( Y=j|X )$$\n",
    "\n",
    "##### K-Nearest Neighbors\n",
    "\n",
    "In theory, we would always like to predict qualitative responses using the Bayes classifier. But in the real world, we might not be able to accurately estimate, let alone know, the conditional distribution of Y given X, so computing the Bayes classifier might be unattainable. \n",
    "**K-Nearest Neighbors (KNN)** - given a positive integer $\\mathbf{K}$ and a test observation $x_0$, the KNN classifier first identifies the K training data points that are clossest to $x_0$, represented by $\\mathcal{N}_0$. It then estimates the conditional probability for class $j$ as the fraction of points in $\\mathcal{N}_0$ whose values equal $j$:\n",
    "$$\\mathbf{Pr}( Y=j|X=x_0) = \\frac{1}{K}\\sum_{i \\in \\mathcal{N}_0} I(y_i=j)$$\n",
    "KNN then classifies the test observation $x_0$ to the class with the largest probability.  \n",
    "The choice of $K$ has a drastic effect on the KNN classifier. Very small $K$ is overly flexible and will overfit the data by finding patterns in the training data that don't exist in the test data (high variance, low bias). As $K$ grows, the method becomes less flexible and produces a decision boundary that approaches linear (low variance, high bias)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Chapter 3 Linear Regression\n",
    "\n",
    "Key ideas underlying the linear regression model, as well as the least squares approach that is most commonly used to fit the model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Simple Linear Regression  \n",
    "\n",
    "**simple linear regression** - predicting a linear quantitative relationship between a response $Y$ and a single predictor variable $X$. We are regressing Y onto X.\n",
    "\n",
    "$$Y \\approx \\beta_o + \\beta_1X$$\n",
    "\n",
    "where the coefficients $\\beta_0$ and $\\beta_1$ are unknown constants that represent the intercept and slope (respectively)  \n",
    "\n",
    "$$\\hat{y} = \\hat(\\beta_o )+ \\hat{\\beta_1}X$$\n",
    "\n",
    "where $\\hat{}$ denotes an estimated or predicted value  \n",
    "\n",
    "#### Estimating the Coefficients  \n",
    "\n",
    "We want to find  an intercept and slope such that the resulting line is as close as possible to the data points.  \n",
    "Measuring closeness:  minimizing the least squares criterion - minimize the sum of the squares of the residuals.  \n",
    "\n",
    "**Least Squares Coefficient Estimte**  \n",
    "\n",
    "$$\\hat{\\beta_1} = \\frac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i-\\bar{x})^2}$$\n",
    "$$\\hat{\\beta_0} = \\bar{y}-\\hat{\\beta_1}\\bar{x}$$\n",
    "\n",
    "#### Assessing the Acurracy of the Coefficient Estimates\n",
    "\n",
    "$$Y \\approx \\beta_o + \\beta_1X + \\epsilon$$\n",
    "\n",
    "In real applications, we have access to a set of observations from which we cn compute the least squares line; however, the population regression line is unobserved  \n",
    "If we estimate $\\beta_0$ and $\\beta_1$ on the basis of a particular data set, then our estimates won't be exaclt equal to the coefficients. But if we could average the estimates obtained over a huge number of data sets, then the average of these estimates would be spot on!  \n",
    "\n",
    "The **standard error** of $\\mu$ - tells us the average amount that the estimate $\\hat{\\mu}$ differs from the actual value of $\\mu$. This value shrinks with $n$: the more values /observations we have, the smaller the standard error of $\\hat{\\mu}$  \n",
    "$$\\mbox{Var}(\\hat{\\mu}) = \\mbox{SE}(\\hat{\\mu})^2 = \\frac{\\sigma^2}{n}$$\n",
    "Usually, SE is unknown. Therefore, we estimate $\\sigma$ from the data as the **residual standard error**: $\\hat{SE}$  \n",
    "Standard errors can be used to compute confidence intervals. for linear regression, the 95% confidence interval for the coefficients takes the form $$\\hat{\\beta_1} \\pm 2 \\cdot \\mbox{SE}(\\hat{\\beta_1})$$ $$\\hat{\\beta_0} \\pm 2 \\cdot \\mbox{SE}(\\hat{\\beta_0})$$  \n",
    "Standard errors can also be used to perform *hypothesis tests*:  \n",
    "\n",
    "* **The Null Hypothesis $H_0$**: there is no relationship between X and Y\n",
    "* **The Alternative Hypothesis $H_1$**: there is some relationship between X and Y\n",
    "\n",
    "we compute the *t-statistic*: $t = \\frac{\\hat{\\beta_1}-0}{\\mbox{SE}(\\hat{\\beta_1})}$  \n",
    "then, we compute the **p-value**, or the probability of observing any number equal $|t|$ or larger in absolute value. A small p-value indicates that it is unlikely to observe such a substantial association between the predictor annd the response due to chance. If the p-value is below a criterion value, we can reject the null hypothesis and declare a relationship exists between X and Y.  \n",
    "\n",
    "#### Assessing the Accuracy of the Model\n",
    "\n",
    "The quality of the regression fit is typically assessed using the **residual standard error (RSE)** and the **$R^2$** statistic:\n",
    "\n",
    "* the RSE is an estimate of the standard deviation of the error $\\epsilon$. it is the average amount that the response will deviate from the true regression line. The RSE can be considered a measure of the lack of fit of the model to the data (large RSE values indicate a poor fit). \n",
    "* the $R^2$ Statistic summarizes the proportion of variability in Y that can be explained using X \n",
    "    - $R^2 = 1 - \\frac{\\mbox{RSS}}{\\mbox{TSS}} = 1 - \\frac{\\mbox{variability left unexplained by the model}}{\\mbox{total variance in the response Y}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Multiple Linear Regression\n",
    "\n",
    "extending the simple linear regression model so that it can accommodate mutiple predictors. We interpret a coefficient $\\beta_j$ as the average effect on Y of a one unit increase in $X_j$, holding all other predictors fixed. \n",
    "$$Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\dots + \\beta_pX_p + \\epsilon$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Estimating the Regression Coefficients\n",
    "\n",
    "use the same least squares approach: choose coefficients to minimize the sum of the squared residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Some Important Questions\n",
    "\n",
    "for MLR:  \n",
    "\n",
    "* Is at least one of the predictors useful in predicting the response?\n",
    "    - test the null hypothesis to see if all $\\beta_{\\geq 1} = 0$ (F-statistic $\\approx$ 1)\n",
    "    - vs the alternative hypothesis that at least one $\\beta_j \\neq 0$ (F-statistic $>$ 1)\n",
    "* Do all predictors help to explain Y, or is only a subset of the predictors useful?\n",
    "    - variable selection: Akaike information, bayesian information, adjuste $R^2$\n",
    "        - consider all possible. might not be feasible\n",
    "        - forward selection. start with the null model\n",
    "        - backward selection. start with the full model\n",
    "        - mixed selection\n",
    "* How well does the model fit the data?\n",
    "    - RSE - models with more parameters have a higher RSE if the decrease in RSS in small relative to the increase in p.\n",
    "    - $R^2 = \\mbox{Cor}(Y.\\hat{Y})^2$\n",
    "    - plotting the data can reveal problems with the model that are not visible from numerical statistics\n",
    "* Given a set of predictor values, what response value should we predict and how accurate is the prediction?\n",
    "    1. the inaccuracy in the coefficient estimates is related to the reducible error. We can compute a confidence interval to find how close $\\hat{Y}$ will be to $f(X)$\n",
    "    2. approximating linearity has model bias\n",
    "    3. because of random error, we cannot perfectly predict even if we have the right model and coefficients\n",
    "    \n",
    "**confidence interval** - quantify the uncertainty surrounding the estimate of the average  \n",
    "**prediction interval** - quantify the uncertainty surrounding the estimate of a particular observation. is typically substantially wider than the confidence interval.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Other Considerations in the Regression Model\n",
    "\n",
    "#### Qualitative Predictors\n",
    "\n",
    "**Predictors with Only Two Levels**  \n",
    "Predictors with only two values can be incorporated into the regression model framework by recoding the variable as a binary *dummy variable* also called **one-hot encoding**. polarity of the coding is completely arbitrary and does not affect the regression outcome, however, it does affect the interpretation of model coefficients.  \n",
    "\n",
    "**Predictors with More than Two Levels**  \n",
    "Add more one-hot encoding. There will always be one fewer dummy variables than the number of levels. The level with no dummy variable is known as the baseline.  \n",
    "\n",
    "#### Extensions of the Linear Model  \n",
    "\n",
    "**additive** - association between predictor and response does not depend on the values of any other predictors  \n",
    "**linear** - change inthe response Y associated with a one-unit change inX is constant regardless of the value of the predictor.  \n",
    "the Linear Model can be extended with several methods that relax both of these assumptions.  \n",
    "\n",
    "**Removing the Additive Assumption** - synergy or interaction effects. One way of extending the linear model to account of interaction effects is to include a parameter called an interaction term that is, for example, a product of the two variables (for a multiplicative effect) in addition to the main effect terms.  \n",
    "**Hierarchy principle** - if we include an interaction term in a model, we should also include the main effects, even if the p-values associated with the coefficients are not significant.  \n",
    "**Extending the Linearity Assumption** - include transformed versions of the predictors, e.g. polynomial regression.  \n",
    "\n",
    "#### Potential Problems\n",
    "\n",
    "1. Non-linearity of the response-predictor relationships\n",
    "    - Residual plots are a useful graphic for assessing non-linearity\n",
    "2. Correlation of error terms\n",
    "    - tracking patterns in the residual as a function of the predictor (e.g. time). residuals form a relational pattern with neighbor observations or intervals or periodicity\n",
    "3. Non-constant variance of error terms\n",
    "    - e.g. **heteroscedasticity** - variance of residuals increases with value of the response\n",
    "    - a cone-like pattern in the residuals\n",
    "    - can counteract by transforming with a concave function\n",
    "4. Outliers\n",
    "    - make educated decisions about removing outliers\n",
    "5. High-Leverage Points\n",
    "    - points with an unusual value for a given x or in terms of the full set of predictors.\n",
    "    - can find the 'leverage statistic'\n",
    "6. Collinearity - when two or more predictor variables are closely related to one another. it can be difficult to separate out the individual effects of colinear responses. the power of a hypothesis test is diminished when colinearity is present in the data.\n",
    "    - solution: either drop the offending features or combine them into a single measure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Chapter 4 Classification\n",
    "\n",
    "**classification** - approaches for predicting qualitative responses  \n",
    "\n",
    "### Why Not a Linear Model?\n",
    "\n",
    "consider a binary qualitative response variable.  \n",
    "It becomes problematic if we fit this data with a linear regressor.  For instance, some of the predictions might be out of the O-1 range making them hard to interpret as probabilities. Additionally, a linear regressor cannot accommodate more than two levels of a response variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### The Logistic Model\n",
    "\n",
    "#### The Logistic Model\n",
    "\n",
    "To yield sensible probability  predictions, we model $p(X)$ using the **logistic function** using **maximum likelihood**  \n",
    "\n",
    "$$p(X) = \\frac{e^{\\beta_0 + \\beta_1X}}{1 + e^{\\beta_0 + \\beta_1X} }$$\n",
    "\n",
    "The logistic function will always produce an S-shaped curve, and so, regardless of the value of $Y$, we get a sensible prediction of $X$.  \n",
    "\n",
    "We can also find that:  \n",
    "$$\\mbox{Odds} = \\frac{p(X)}{1-p(X)} = e^{\\beta_0 + \\beta_1X}$$\n",
    "\n",
    "Which leads to the **logit**, or log odds function:\n",
    "$$\\mbox{log}\\left(\\frac{p(X)}{1-p(X)}\\right) = \\beta_0 + \\beta_1X$$\n",
    "\n",
    "Interpretting the logistic model: increasing X by one unit changes the log odds by  $\\beta_1$. $p(X)$ does not have a straight line relationship with X, and the rate of change of $p(X)$ depends on the value of X.  \n",
    "\n",
    "#### Estimating the Regression Coefficients\n",
    "\n",
    "**maximum likelihood** - seek estimates for the coefficients such that the predicted probability of default for each individual, corresponds as closely as possible to the individual's observed default status.\n",
    "\n",
    "$$\\mathcal{l}(\\beta_0,\\beta_1)= \\prod_{i:y_1=1}p(x_i) \\prod_{i':y_i'=0}(1-p(x_i'))$$\n",
    "\n",
    "chose estimates of the coefficient to maximize the likelihood function.  \n",
    "\n",
    "#### Multiple Logistic Regression\n",
    "\n",
    "$$\\mbox{log}\\left(\\frac{p(X)}{1-p(X)}\\right) = \\beta_0 + \\beta_1X + \\dots + \\beta_xX_p$$\n",
    "\n",
    "#### Multinomial Logistic Regression\n",
    "\n",
    "classify a response variable that has more than two classes.  \n",
    "first, select a class to serve as the baseline; e.g. the *k*th class:\n",
    "\n",
    "$$p(Y=k|X=x) = \\frac{e^{\\beta_{k_0} + \\beta_{k_1}x_1 + \\dots + \\beta_{k_p}x_p}}{1 + e^{\\beta_{l0 }+ \\beta_{l1}x_1 + \\dots + \\beta{l_p}x_p} }$$\n",
    "\n",
    "$$\\mbox{log}\\left(\\frac{\\mbox{Pr}(Y=k|X=x)}{\\mbox{Pr}(Y=K|X=x)}\\right) = \\beta_{k_0} + \\beta_{k_1}x_1 + \\dots + \\beta_{k_p}x_p$$\n",
    "\n",
    "the log odds between any pair of classes is linear in the features.  \n",
    "interpretation of the coefficients in a multinomial logistic regression model must be done with care, since it is tied to the choice of baseline.  \n",
    "\n",
    "Alternative: **softmax coding** - rather than selecting a baseline class, we treat all K classes symmetrically:  \n",
    "\n",
    "$$p(Y=k|X=x) = \\frac{e^{\\beta_{k_0} + \\beta_{k_1}x_1 + \\dots + \\beta_{k_p}x_p}}{\\sum_{l=1}^K e^{\\beta_{l0 }+ \\beta_{l1}x_1 + \\dots + \\beta{l_p}x_p} }$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
