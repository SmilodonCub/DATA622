{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# An Introduction to Statistical Learning\n",
    "with Applications in `R`  \n",
    "Second Edition  \n",
    "Gareth James $\\cdot$ Daniela Witten $\\cdot$ Trevor Hastie $\\cdot$ Robert Tibshirani  \n",
    "\n",
    "Notes by Bonnie Cooper and working out the examples in `Python`  \n",
    "for the course, DATA 622: Machine Learning and Big Data  \n",
    "\n",
    "\n",
    "<img src=\"https://images-na.ssl-images-amazon.com/images/I/41pP5+SAv-L._SX330_BO1,204,203,200_.jpg\" width=\"20%\" style=\"margin-left:auto; margin-right:auto\">\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**statistical learning** - making sense of complex data sets  \n",
    "**supervised statistical learning** - building a statistical model for predicting or estimating an output based on one of more inputs  \n",
    "**unsupervised statistical learning** - there are inputs, but no supervising outputs; nevertheless, we can learn about relationships and structure in the data.  \n",
    "\n",
    "The goal of this book: become informed users. for technical detail, work through the [ESL](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)  \n",
    "*While it is important to know what job is performed by each cog, it is not necessary to have the skills to construct the machine inside the box!*  \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### Notation\n",
    "\n",
    "* $n$ - number of distinct data points\n",
    "* $p$ - number of feature variables\n",
    "* $\\mathbf{X}$ - an $n \\times p$ matrix whose $(i,j)$th element is represented as $x_{ij}$\n",
    "* $\\mathbf{y}$ - the set of all $n$ observations in vector form\n",
    "* $a \\in \\mathbb{R}$ - a scalar\n",
    "* $a \\in \\mathbb{R}^k$ - a vector with length k\n",
    "* $a \\in \\mathbb{R}^[k\\times d]$ - a matix\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2 Statistical Learning\n",
    "\n",
    "$\\mathbf{X}$ - the response or dependent variable  \n",
    "$\\mathbf{Y}$ - the predictor(s), independent variable(s) or feature(s)  \n",
    "\n",
    "We assume that there is a relationship between $\\mathbf{Y}$ and $\\mathbf{X}$ such that:  \n",
    "$$\\mathbf{Y} = f(\\mathbf{X}) + \\epsilon $$\n",
    "\n",
    "where:  \n",
    "$f$ - some fixed function (undetermined)  \n",
    "$\\epsilon$ - a random error term  \n",
    "\n",
    "Our goal: estimate $f$ based on the given observations  \n",
    "\n",
    "### What is Statistical Learning?\n",
    "\n",
    "#### Why Estimate $f$?\n",
    "\n",
    "**Prediction** - predict $\\mathbf{Y}$ using $\\hat{ \\mathbf{Y} } = \\hat{f} (\\mathbf{X})$  \n",
    "The accuracy of $\\hat{\\mathbf{Y}}$ depends on two quantities: the reducible error and the irreducible error  \n",
    "**reducible error** - error in our estimate of $f$  \n",
    "**irreducible error** - error in $\\mathbf{Y}$  \n",
    "**expected value** - the squared difference between the actual and the estimated value of $\\mathbf{Y}$  \n",
    "\n",
    "$$\\mathbf{E}(\\mathbf{Y}- \\hat{\\mathbf{Y}})^2 = \\mathbf{E}[f(\\mathbf{X}+\\epsilon -\\hat{f}(\\mathbf{X})]^2] = [f(\\mathbf{X})-\\hat{f}(\\mathbf{X})]^2 + \\mbox{Var}(\\epsilon)$$\n",
    "\n",
    "\n",
    "**Inference** - understand the association between $\\mathbf{Y}$ and $\\mathbf{X}_1,\\dots,\\mathbf{X}_p$  \n",
    "\n",
    "#### How Do We Estimate $f$?\n",
    "\n",
    "Our goal is to apply statistical learning to our training data to estimate the unknown function $f$. Basically, we want to find an estimate of $f$ which we will call $\\hat{f}$ such the $\\mathbf{Y}  \\approx \\hat{f}( \\mathbf{X})$  \n",
    "\n",
    "* **Paramteric approach** - involves a two-step model-based  \n",
    "    * make an assumption about the form of the data (ex: assume linearity)\n",
    "    * use a procudure to train and fit the assumed model\n",
    "    * problem: the model we chose will usually not match the true form of $f$\n",
    "* **Nonparametric methods** - make no assumptions about the form of $f$   \n",
    "    * estimate $f$ by getting as close to data points\n",
    "    * problem: since nonparametric methods do not reduce the problem of estimating $f$ to a small number of parameters, a comparatively larger number of observations are required in order to get an accurate estimate of $f$.\n",
    "    \n",
    "#### The Trade off Between Prediction Accuracy and Model Interpretability\n",
    "\n",
    "*Why would we ever choose to use a more restrictive method instead of a very flexible approach?*   \n",
    "Often, more restrictive models (e.g. linear regression) are more easily interpretable. However, in some settings we are only interested in the prediction, and the interpretability of the predictive model is simply not of interest; here we might expect that it will be best to use the more flexible model provided the model does not overfit.  \n",
    "\n",
    "#### Supervised Vs Unsupervised Learning \n",
    "\n",
    "**Supervised Learning** - for each observation of the predictor measurement, there is an associated response measure. Goal: fit a model that relates the response to the predictors so that we may (1) accurately predict future responses from the observations and (2) better understand the relationship between the response and the predictors.  \n",
    "**Unsupervised Learning** - for every observation, we observe a vector of features, but no associated response. This situation is called unsupervised, because we lack a response variable that can supervise our analysis.  \n",
    "\n",
    "#### Regression vs Classification Problems\n",
    "\n",
    "**quantitive variables** - take on numeric values  \n",
    "**qualitative variables** - take on categorical values  \n",
    "**regression problems** - the reponse is a quantitative variable\n",
    "**classification problems** - the response is a qualitative variable  \n",
    "most of the statistical learning methods discussed in this book can be applied regardless of the predictor variable type, provided that any qualitative predictors are properly coded before the analysis is performed.  \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing Model Accuracy\n",
    "\n",
    "*There is no free lunch in statistics* - no onemethod dominates all others over all possible data sets  \n",
    "\n",
    "#### Measureing Quality of Fit\n",
    "\n",
    "**mean squared error** -a measure of how well a models predictions acutally match the observed data. The MSE will be small if the predicted responses are very close to the truw responses and will be large if for some of the observations, the predicted and true responses differ substantially.   \n",
    "$$\\mathbf{MSE} = \\frac{1}{n} \\sum_{i=1}^{n}( y_i - \\hat{f} (x_i))^2$$\n",
    "We are interested in the accuracy of the predictions that we obtain when we apply out method to previously unseen test data. We want to choose the method which gives the lowest *test* MSE, as opposed to the lowest *traininng* MSE. In other words, we'd like to select a model that minimizes:  \n",
    "$$\\mathbf{Ave}(y_0 - \\hat{f}(x_0))^2$$\n",
    "where $(x_0,y_0)$ is a previously unseen test observation not ued to train the model.  \n",
    "\n",
    "**overfitting** - when a given method yields a small training $\\mathbf{MSE}$ but a large test $\\mathbf{MSE}$. When a less flexible model would have given a lower test $\\mathbf{MSE}$   \n",
    "\n",
    "#### The Bias-Variance Trade-Off  \n",
    "\n",
    "the Expected test $\\mathbf{MSE}$, for a given value of $x_0$ can always be decomposed into the sum of three fundamental qualities: the variance of $\\hat{f} (x_0)$, the square of the bias of $\\hat{f} (x_0)$ and the variance of the error terms $\\epsilon$:  \n",
    "$$\\mathbf{E}(y_0 - \\hat{f}(x_0))^2) = \\mathbf{Var}(\\hat{f}(x_0)) + [\\mathbf{Bias}(\\hat{f}(x_0))]^2 + \\mathbf{Var}(\\epsilon)$$\n",
    "\n",
    "What this tells is is, that in order to minimize the expected test error, we need to select a statistical learning method that simultaniously achieves **low variance** nd **low bias**. where:  \n",
    "**variance** - the amount that $\\hat{f}$ would change if we estimated it using a different training set. If a methods has high variance, then a small change to the data set would lead to a large change in $\\hat{f}$  \n",
    "**bias** - the error that is introduced by approximaating a real-life problem (choice of estimating $f$)  \n",
    "\n",
    "In general, as we use more flexible methods, the variance will increase and the bias will decrease.  \n",
    "**bias-variance trade-off** - the relationship between bias, variance, and test $\\mathbf{MSE}$. The challenge lies in finding a method for which both the variance and the squared bias are low.   \n",
    "\n",
    "#### The Classification Setting  \n",
    "\n",
    "Quantifying accuracy of a classification problem: the training error rate  \n",
    "$$\\frac{1}{n}\\sum_{i=1}^n \\mathbf{I}(y_1 \\neq \\hat{y}_i)$$\n",
    "**error rate**  - proportion of mistakes that are made if we apply our estimate $\\hat{f}$ to the training observations  \n",
    "**test error rate** $\\mathbf{Ave}(\\mathbf{I}(y_0 \\neg \\hat{y}_0))$ a good classifier is one for which the test error is smallest.  \n",
    "\n",
    "##### The Bayes Classifier \n",
    "\n",
    "**Bayes Classifier** - assign each observation to the most likely class, given its predictor values.\n",
    "$$\\mathbf{Pr}( Y= j | X = x_0 )$$\n",
    "**Bayesian Decision Boundary** boundary in feature space where the conditional probability of either events is equal. An observation that falls on one side of the boundary will be classified as one class whereas the other side the other.\n",
    "A Bayes Classifier produces the lowest possible test error rate, the **Bayes Error Rate**. the Bayes error rate is analogous to the irreducible error.  \n",
    "$$1 - \\mathbf{E}(max_j \\mathbf{Pr}( Y=j|X )$$\n",
    "\n",
    "##### K-Nearest Neighbors\n",
    "\n",
    "In theory, we would always like to predict qualitative responses using the Bayes classifier. But in the real world, we might not be able to accurately estimate, let alone know, the conditional distribution of Y given X, so computing the Bayes classifier might be unattainable. \n",
    "**K-Nearest Neighbors (KNN)** - given a positive integer $\\mathbf{K}$ and a test observation $x_0$, the KNN classifier first identifies the K training data points that are clossest to $x_0$, represented by $\\mathcal{N}_0$. It then estimates the conditional probability for class $j$ as the fraction of points in $\\mathcal{N}_0$ whose values equal $j$:\n",
    "$$\\mathbf{Pr}( Y=j|X=x_0) = \\frac{1}{K}\\sum_{i \\in \\mathcal{N}_0} I(y_i=j)$$\n",
    "KNN then classifies the test observation $x_0$ to the class with the largest probability.  \n",
    "The choice of $K$ has a drastic effect on the KNN classifier. Very small $K$ is overly flexible and will overfit the data by finding patterns in the training data that don't exist in the test data (high variance, low bias). As $K$ grows, the method becomes less flexible and produces a decision boundary that approaches linear (low variance, high bias)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
